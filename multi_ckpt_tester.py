import os
import torch
import numpy as np
from PIL import Image
from PIL.PngImagePlugin import PngInfo
import json
import gc  # å¼•å…¥åƒåœ¾å›æ”¶æ¨¡å—
import traceback

import comfy.sd
import comfy.utils
import nodes
import folder_paths
import comfy.model_management

class MultiCheckpointIncrementalNamer:
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()

    @classmethod
    def INPUT_TYPES(s):
        checkpoints = folder_paths.get_filename_list("checkpoints")
        return {
            "required": {
                "ckpt_name_1": (checkpoints,),
                "positive_prompt": ("STRING", {"multiline": True, "default": "1girl, cinematic lighting"}),
                "negative_prompt": ("STRING", {"multiline": True, "default": "low quality, blurry"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "steps": ("INT", {"default": 20, "min": 1}),
                "cfg": ("FLOAT", {"default": 7.5, "min": 0.0}),
                "sampler_name": (comfy.samplers.KSampler.SAMPLERS, ),
                "scheduler": (comfy.samplers.KSampler.SCHEDULERS, ),
                "denoise": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}),
                "width": ("INT", {"default": 512, "step": 8}),
                "height": ("INT", {"default": 512, "step": 8}),
            },
            "optional": {
                "ckpt_name_2": (["None"] + checkpoints,),
                "ckpt_name_3": (["None"] + checkpoints,),
                "ckpt_name_4": (["None"] + checkpoints,),
                "ckpt_name_5": (["None"] + checkpoints,),
            },
            "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"},
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "run_test"
    CATEGORY = "CustomNodes/Test"
    OUTPUT_NODE = True

    def get_unique_path(self, base_name):
        filename = f"{base_name}.png"
        full_path = os.path.join(self.output_dir, filename)
        if os.path.exists(full_path):
            counter = 1
            while True:
                suffix = f"_{counter:02d}"
                filename = f"{base_name}{suffix}.png"
                full_path = os.path.join(self.output_dir, filename)
                if not os.path.exists(full_path):
                    break
                counter += 1
        return full_path

    def run_test(self, ckpt_name_1, positive_prompt, negative_prompt, seed, steps, cfg, sampler_name, scheduler, denoise, width, height, prompt=None, extra_pnginfo=None, **kwargs):
        # æ”¶é›†æ‰€æœ‰éç©ºçš„æ¨¡å‹åç§°
        selected_ckpts = [ckpt_name_1]
        for i in range(2, 6):
            name = kwargs.get(f"ckpt_name_{i}")
            if name and name != "None":
                selected_ckpts.append(name)

        final_images_list = []
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = PngInfo()
        if prompt is not None:
            metadata.add_text("prompt", json.dumps(prompt))
        if extra_pnginfo is not None:
            for x in extra_pnginfo:
                metadata.add_text(x, json.dumps(extra_pnginfo[x]))

        for full_name in selected_ckpts:
            clean_name = os.path.splitext(os.path.basename(full_name))[0]
            print(f"ğŸ”„ [Multi-Ckpt] æ­£åœ¨å¤„ç†æ¨¡å‹: {clean_name}")

            # åˆå§‹åŒ–å˜é‡é˜²æ­¢ finally ä¸­å¼•ç”¨æœªå®šä¹‰å˜é‡
            model = clip = vae = sample = None
            
            try:
                # 1. åŠ è½½æ¨¡å‹
                ckpt_path = folder_paths.get_full_path("checkpoints", full_name)
                # ä½¿ç”¨ comfy çš„åŠ è½½å™¨
                out = comfy.sd.load_checkpoint_guess_config(
                    ckpt_path, 
                    output_vae=True, 
                    output_clip=True, 
                    embedding_directory=folder_paths.get_folder_paths("embeddings")
                )
                model, clip, vae = out[0], out[1], out[2]

                # 2. ç¼–ç  Prompt
                tokens_pos = clip.tokenize(positive_prompt)
                cond_pos, pooled_pos = clip.encode_from_tokens(tokens_pos, return_pooled=True)
                positive = [[cond_pos, {"pooled_output": pooled_pos}]]

                tokens_neg = clip.tokenize(negative_prompt)
                cond_neg, pooled_neg = clip.encode_from_tokens(tokens_neg, return_pooled=True)
                negative = [[cond_neg, {"pooled_output": pooled_neg}]]

                # 3. é‡‡æ · (KSampler)
                latent = torch.zeros([1, 4, height // 8, width // 8], device=comfy.model_management.get_torch_device())
                samples = {"samples": latent}
                
                # æ‰§è¡Œé‡‡æ ·
                sample = nodes.common_ksampler(
                    model, seed, steps, cfg, sampler_name, scheduler, 
                    positive, negative, samples, denoise=denoise
                )[0]

                # 4. è§£ç  (VAE Decode) -> è¾“å‡ºé€šå¸¸æ˜¯ [1, C, H, W]
                # æ³¨æ„ï¼šVAE è§£ç éœ€è¦åœ¨ GPU ä¸Šè¿›è¡Œä»¥æé«˜é€Ÿåº¦ï¼Œä½†è¦å°å¿ƒæ˜¾å­˜
                decoded_tensor = vae.decode(sample["samples"])

                # --- å…³é”®ä¿®å¤ 1: ç»´åº¦è½¬æ¢ ---
                # ä» [Batch, Channel, Height, Width] è½¬æ¢ä¸º [Batch, Height, Width, Channel]
                # è¿™æ˜¯ ComfyUI å›¾åƒç®¡é“çš„æ ‡å‡†æ ¼å¼
                if decoded_tensor.shape[1] == 3: # ç¡®ä¿æ˜¯ C åœ¨ç¬¬äºŒç»´
                    decoded_tensor = decoded_tensor.permute(0, 2, 3, 1)
                
                # å°†å¤„ç†å¥½çš„ Tensor åŠ å…¥åˆ—è¡¨ç”¨äºæœ€åè¿”å›
                # å°† Tensor ç§»å› CPU ä»¥èŠ‚çœæ˜¾å­˜ï¼Œé˜²æ­¢åœ¨åˆ—è¡¨ä¸­å †ç§¯å ç”¨ GPU
                final_images_list.append(decoded_tensor.cpu())

                # 5. ä¿å­˜å›¾ç‰‡
                save_path = self.get_unique_path(clean_name)
                
                # è½¬æ¢ç”¨äº PIL ä¿å­˜: 
                # tensor [1, H, W, C] -> squeeze -> [H, W, C] -> numpy
                img_array = 255. * decoded_tensor.cpu().numpy().squeeze()
                img_pil = Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))
                
                img_pil.save(save_path, pnginfo=metadata, compress_level=4)
                print(f"âœ… [Multi-Ckpt] æˆåŠŸä¿å­˜: {save_path}")

            except Exception as e:
                # --- å…³é”®ä¿®å¤ 3: å¼‚å¸¸æ•è· ---
                print(f"âŒ [Multi-Ckpt] å¤„ç†æ¨¡å‹ {clean_name} æ—¶å‘ç”Ÿé”™è¯¯:\n{traceback.format_exc()}")
                # å¯ä»¥é€‰æ‹©æ·»åŠ ä¸€ä¸ªå…¨é»‘å›¾ç‰‡å ä½ï¼Œæˆ–è€…ç›´æ¥è·³è¿‡
                continue

            finally:
                # --- å…³é”®ä¿®å¤ 2: æš´åŠ›æ˜¾å­˜æ¸…ç† ---
                # æ˜¾å¼åˆ é™¤å¼•ç”¨
                del model, clip, vae, sample
                # å¼ºåˆ¶ Python åƒåœ¾å›æ”¶ (å¤„ç†å¾ªç¯å¼•ç”¨)
                gc.collect()
                # å¼ºåˆ¶ PyTorch é‡Šæ”¾ç¼“å­˜æ˜¾å­˜
                comfy.model_management.soft_empty_cache()

        # æœ€ç»ˆåˆå¹¶
        if len(final_images_list) > 0:
            # cat é»˜è®¤åœ¨ dim=0 åˆå¹¶: [1,H,W,C] + [1,H,W,C] -> [N,H,W,C]
            return (torch.cat(final_images_list, dim=0),)
        else:
            # å¦‚æœå…¨éƒ¨å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªç©ºçš„é»‘è‰²å›¾ç‰‡é˜²æ­¢ä¸‹æ¸¸æŠ¥é”™
            print("âš ï¸ [Multi-Ckpt] æ‰€æœ‰æ¨¡å‹å‡å¤„ç†å¤±è´¥ï¼Œè¿”å›ç©ºç™½å›¾åƒã€‚")
            empty_img = torch.zeros((1, height, width, 3), dtype=torch.float32)
            return (empty_img,)

NODE_CLASS_MAPPINGS = {
    "MultiCheckpointIncrementalNamer": MultiCheckpointIncrementalNamer
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "MultiCheckpointIncrementalNamer": "Multi-Checkpoint (Auto Incremental Name)"
}